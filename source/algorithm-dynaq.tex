\section{The multi-objective \acronymBaseline{}{} algorithm}
\label{appendix:algorithm-qrouting}

%%%%%%%%%%%%%%%%%%%
\newcommand{\functionEGreedy}[2]{
	\functionSignature{\epsilon\text{-greedy}}{#1}
}
%%%%%%%%%%%%%%%%

The variation of Q-routing we use for comparison utilises the same multi-objective reward function as \acronymWSNOptimisation{}{}. It also assumes full knowledge and neighbourhood containing all agents in the system. The algorithm uses the update function for actions to Q-value mappings from the \acronymATARIA{}{} algorithm. In comparison to the \acronymATARIA{}{} algorithm, it uses $\functionEGreedy{}{}$ selection for choosing actions instead of \acronymRewardTrendsAlgorithm{}{}, and does not attempt to learn actions relating to knowledge and neighbourhood as agents assume full system information. This algorithm follows strategies developed from Q-routing \citep{Boyan}, but without low-level details on node communications and protocols. This is comparable in particular to work that adds energy-awareness and adaptive routing \citep{Kiani2015, Wang2006, Khan2021}. We also adapt the application of Q-learning to fit the multi-agent, task-based framework.

\begin{algorithm}[ht]
	\DontPrintSemicolon
	\footnotesize
	
	\caption{\textbf{The multi-objective \acronymBaseline{}{} algorithm}}
	\label{alg:qrouting}
	{
		\KwIn{ $\varAgent{}{}$ , The agent allocated the composite task}
		\KwIn{ $\varCompositeTask{}{}$ , The composite task allocated to the agent}
		\KwIn{$\setAtomicTaskUnallocated{}{}$, The composite tasks currently unallocated atomic tasks}	\KwIn{$\functionInstanceQMappingSignature{}{}$, the Q-values mappings for agent $\varAgent{}{}$ }
		\KwIn{\defVarLearningRate{}{}{}}
		\KwIn{\defVarDiscountFactor{}{}{}}
		\nonl \;

		\KwResult{$\functionInstanceQMappingSignature{}{}$, updates to the Q-mapping of agent $\varAgent{}{}$}

		\nonl \;
		
		\For{$\varAtomicTask{}{} \in \varCompositeTask{}{} $}
		{
			$\varAction{}{} \leftarrow \functionEGreedy{\functionInstanceQMappingSignature}{}$\;		
			\uIf{$\varAction{}{} = \functionActionExecSignature{}{}$}
			{
				$\functionActionExecSignature{}{}$\; \label{qrouting:doexec}
				\If {$\varAtomicTask{}{}$ is successfully completed}
				{
					$\varCompositeTask{}{} \leftarrow \varCompositeTask{}{} - \lbrace \varAtomicTask{}{} \rbrace$ \;
				}\label{qrouting:hascapabilityend}
			}
			\uElseIf{$\varAction{}{} = \functionActionAllocSignature{}{}$}
			{
					$\functionActionAllocSignature{}{}$\; \label{qrouting:doalloc}
					
					\If {$\varAtomicTask{}{}$ is successfully completed}
					{
						$\varCompositeTask{}{} \leftarrow \varCompositeTask{}{} - \lbrace \varAtomicTask{}{} \rbrace$ \;
					}
			}\label{qrouting:hasallocend}
			\tcp{Update Q-value mappings with reward}
			$\functionInstanceQMappingSignature{}{} \leftarrow \functionTDUpdateSignature{}{}$\;\label{qrouting:updateq}
		}
		\Return{$\functionInstanceQMappingSignature{}{}$}
}
\end{algorithm}